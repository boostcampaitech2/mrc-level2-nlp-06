{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from contextlib import contextmanager\n",
    "from typing import List, Tuple, NoReturn, Any, Optional, Union\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments, \n",
    "    BertPreTrainedModel,\n",
    "    BertModel,AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    RobertaConfig, \n",
    "    RobertaModel,\n",
    "    PreTrainedModel)\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    "    Features,\n",
    "    Value,\n",
    "    DatasetDict,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from retrieval import *\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wiki_preprocess(text):\n",
    "            text = re.sub(r'\\n', ' ', text)\n",
    "            text = re.sub(r\"\\\\n\", \" \", text)\n",
    "            text = re.sub(r'\\\\n\\\\n', ' ', text)\n",
    "            text = re.sub(r'\\n\\n', \" \", text)\n",
    "            text = re.sub(r\"\\s+\", \" \", text)\n",
    "            text = re.sub(r'#', ' ', text)\n",
    "            return text \n",
    "\n",
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)\n",
    "\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "dataset = \"../data/train_dataset\"\n",
    "org_dataset = load_from_disk(dataset)\n",
    "train_datasets = org_dataset['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpath = \"../data/test_dataset\"\n",
    "test = load_from_disk(tpath)['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_dataset = org_dataset['validation']\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "\n",
    "q_seqs = tokenizer(train_datasets['question'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "p_seqs = tokenizer(train_datasets['context'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "\n",
    "train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'], \n",
    "                        q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids'])\n",
    "# train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], \n",
    "#                         q_seqs['input_ids'], q_seqs['attention_mask'])\n",
    "\n",
    "class BertEncoder(BertPreTrainedModel):\n",
    "  def __init__(self, config):\n",
    "    super(BertEncoder, self).__init__(config)\n",
    "\n",
    "    self.bert = BertModel(config)\n",
    "    self.init_weights()\n",
    "      \n",
    "  def forward(self, input_ids, \n",
    "              attention_mask=None, token_type_ids=None): \n",
    "  \n",
    "      outputs = self.bert(input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids)\n",
    "      \n",
    "      pooled_output = outputs[1]\n",
    "\n",
    "      return pooled_output\n",
    "\n",
    "\n",
    "# load pre-trained model on cuda (if available)\n",
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=11,\n",
    "    weight_decay=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "            {\"params\": [p for n, p in p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in p_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "            {\"params\": [p for n, p in q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in q_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "        ]\n",
    "optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=args.learning_rate,\n",
    "            eps=args.adam_epsilon\n",
    "        )\n",
    "\n",
    "def train(args, dataset, p_model, q_model):\n",
    "  \n",
    "  # Dataloader\n",
    "  train_sampler = RandomSampler(dataset)\n",
    "  train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=args.per_device_train_batch_size)\n",
    "\n",
    "  t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "  # Start training!\n",
    "  global_step = 0\n",
    "  \n",
    "  p_model.zero_grad()\n",
    "  q_model.zero_grad()\n",
    "  torch.cuda.empty_cache()\n",
    "  \n",
    "  train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "  for _ in train_iterator:\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "      q_encoder.train()\n",
    "      p_encoder.train()\n",
    "      \n",
    "      if torch.cuda.is_available():\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "      p_inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'token_type_ids': batch[2]\n",
    "                  }\n",
    "      \n",
    "      q_inputs = {'input_ids': batch[3],\n",
    "                  'attention_mask': batch[4],\n",
    "                  'token_type_ids': batch[5]}\n",
    "\n",
    "      p_outputs = p_model(**p_inputs)  # (batch_size, emb_dim)\n",
    "      q_outputs = q_model(**q_inputs)  # (batch_size, emb_dim)\n",
    "\n",
    "\n",
    "      # Calculate similarity score & loss\n",
    "      sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1))  # (batch_size, emb_dim) x (emb_dim, batch_size) = (batch_size, batch_size)\n",
    "\n",
    "      # target: position of positive samples = diagonal element \n",
    "      targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
    "      if torch.cuda.is_available():\n",
    "        targets = targets.to('cuda')\n",
    "\n",
    "      sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "\n",
    "      loss = F.nll_loss(sim_scores, targets)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "      q_model.zero_grad()\n",
    "      p_model.zero_grad()\n",
    "      global_step += 1\n",
    "      \n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    \n",
    "  return p_model, q_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:30<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:29<00:00,  1.33s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:29<00:00,  1.34s/it]\n",
      "Iteration: 100%|██████████| 247/247 [05:29<00:00,  1.34s/it]\n",
      "Epoch: 100%|██████████| 11/11 [1:00:32<00:00, 330.21s/it]\n"
     ]
    }
   ],
   "source": [
    "p_encoder, q_encoder = train(args, train_dataset, p_encoder, q_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_encoder.save_pretrained('../qe')\n",
    "# p_encoder.save_pretrained('../pe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_encoder.load_state_dict(torch.load(\"../dpr/p_encoder_14_b4_lr8e-6_neg2.pt\"))\n",
    "q_encoder.load_state_dict(torch.load(\"../dpr/q_encoder_14_b4_lr8e-6_neg2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_encoder.load_state_dict(torch.load(\"../dpr/best_p_enc_model.pt\"))\n",
    "q_encoder.load_state_dict(torch.load(\"../dpr/best_q_enc_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/wikipedia_documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            wiki = json.load(f)\n",
    "\n",
    "contexts = list(\n",
    "            dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    "        ) \n",
    "query = valid_dataset['question']\n",
    "ground_truth = valid_dataset['context']\n",
    "valid_corpus = contexts\n",
    "# query = train_datasets['question'][:1000]\n",
    "# ground_truth = train_datasets['context'][:1000]\n",
    "# valid_corpus = train_datasets['context'][:1000]\n",
    "\n",
    "def to_cuda(batch):\n",
    "  return tuple(t.cuda() for t in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(len(contexts)):\n",
    "#     contexts[idx] = wiki_preprocess(contexts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(len(ground_truth)):\n",
    "#     ground_truth[idx] = wiki_preprocess(ground_truth[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56737, 56737)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexts), len(list(set(contexts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts = list(set(contexts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "crt = 0\n",
    "for i in ground_truth:\n",
    "    if i in valid_corpus:\n",
    "        crt+=1\n",
    "print(crt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56737/56737 [16:50<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56737, 768]) torch.Size([240, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  p_encoder.eval()\n",
    "  q_encoder.eval()\n",
    "\n",
    "  q_seqs_val = tokenizer(query, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "  q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "\n",
    "  p_embs = []\n",
    "  for p in tqdm(valid_corpus):\n",
    "    p = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "    p_emb = p_encoder(**p).to('cpu').numpy()\n",
    "    p_embs.append(p_emb)\n",
    "\n",
    "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "\n",
    "print(p_embs.size(), q_emb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([240, 768]), torch.Size([768, 56737]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_emb.size(),torch.transpose(p_embs, 0, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 56737])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "print(dot_prod_scores.size())\n",
    "\n",
    "ranks = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "context_list = []\n",
    "\n",
    "for index in range(len(ranks)):\n",
    "    k_list = []\n",
    "    for i in range(k):\n",
    "        k_list.append(valid_corpus[ranks[index][i]])\n",
    "    context_list.append(k_list)\n",
    "correct= 0\n",
    "for index in range(len(ground_truth)):\n",
    "    if ground_truth[index] in context_list[index]:\n",
    "        correct+=1 \n",
    "print(correct/len(context_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "config = BertConfig.from_json_file('../qe/config.json')\n",
    "q_encoder = BertEncoder.from_pretrained('../qe/pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_json_file('../pe/config.json')\n",
    "p_encoder = BertEncoder.from_pretrained('../pe/pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_fn = tokenizer.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55963"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56737/56737 [18:22<00:00, 51.46it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  p_encoder.eval()\n",
    "  tokenized_corpus = []\n",
    "  p_embs = []\n",
    "  for p in tqdm(valid_corpus):\n",
    "    p_t = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "    p_emb = p_encoder(**p_t).to('cpu').numpy()\n",
    "    p_embs.append(p_emb)\n",
    "    tokenized_corpus.append(tokenize_fn(p, padding=\"max_length\", truncation=True, return_tensors='pt'))\n",
    "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56737, 768]) torch.Size([240, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  q_encoder.eval()\n",
    "  q_seqs_val = tokenizer(query, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "  q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "\n",
    "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "\n",
    "print(p_embs.size(), q_emb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_top_n(bm25, query, documents, n=10):\n",
    "#     assert bm25.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
    "\n",
    "#     scores = bm25.get_scores(query)\n",
    "\n",
    "#     top_n_idx = np.argsort(scores)[::-1][:n]\n",
    "#     doc_score = scores[top_n_idx]\n",
    "        \n",
    "#     return doc_score, top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval import MyBm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_embedding(bm25,contexts, tokenize_fn,data_path =\"../\",k1=1.5, b=0.75, epsilon=0.25) -> NoReturn:\n",
    "\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        Passage Embedding을 만들고\n",
    "        TFIDF와 Embedding을 pickle로 저장합니다.\n",
    "        만약 미리 저장된 파일이 있으면 저장된 pickle을 불러옵니다.\n",
    "    \"\"\"\n",
    "    bm25_name = f\"bm25.bin\"\n",
    "    bm25_path = os.path.join(data_path, bm25_name)\n",
    "    if os.path.isfile(bm25_path):\n",
    "        with open(bm25_path, \"rb\") as file:\n",
    "            bm25 = pickle.load(file)\n",
    "        print(\"Embedding bm25 pickle load.\")\n",
    "    else:\n",
    "        print(\"Building bm25... It may take 1 minute and 30 seconds...\")\n",
    "        # bm25 must tokenizer first \n",
    "        # because it runs pool inside and this cuases unexpected result.\n",
    "        tokenized_corpus = []\n",
    "        for c in contexts:\n",
    "            tokenized_corpus.append(tokenize_fn(c))\n",
    "        bm25 = MyBm25(tokenized_corpus, k1 = k1, b = b, epsilon=epsilon)\n",
    "        with open(bm25_path, \"wb\") as file:\n",
    "            pickle.dump(bm25, file)\n",
    "        print(\"bm25 pickle saved.\")\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = MyBm25(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building bm25... It may take 1 minute and 30 seconds...\n",
      "bm25 pickle saved.\n"
     ]
    }
   ],
   "source": [
    "bm25 = get_sparse_embedding(bm25,contexts,tokenize_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법시험에 합격하여 판사로 임용되었고 대법원 재판연구관, 수원지법 부장판사, 사법연수원 교수, 특허법원 부장판사 등을 거쳐 능력을 인정받았다. 2003년 최종영 대법원장의 지명으로 헌법재판소 재판관을 역임하였다.\\\\n\\\\n경제민주화위원회(위원장 장하성이 소액주주들을 대표해 한보철강 부실대출에 책임이 있는 이철수 전 제일은행장 등 임원 4명을 상대로 제기한 손해배상청구소송에서 서울지방법원 민사합의17부는 1998년 7월 24일에 \"한보철강에 부실 대출하여 은행에 막대한 손해를 끼친 점이 인정된다\"며 \"원고가 배상을 청구한 400억원 전액을 은행에 배상하라\"고 하면서 부실 경영인에 대한 최초의 배상 판결을 했다. \\\\n\\\\n2004년 10월 신행정수도의건설을위한특별조치법 위헌 확인 소송에서 9인의 재판관 중 유일하게 각하 견해를 내었다. 소수의견에서 전효숙 재판관은 다수견해의 문제점을 지적하면서 관습헌법 법리를 부정하였다. 전효숙 재판관은 서울대학교 근대법학교육 백주년 기념관에서 열린 강연에서, 국회가 고도의 정치적인 사안을 정치로 풀기보다는 헌법재판소에 무조건 맡겨서 해결하려는 자세는 헌법재판소에게 부담스럽다며 소회를 밝힌 바 있다.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스카버러 남쪽과 코보콘그 마을의 철도 노선이 처음 연장된 연도는?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = bm25.get_scores(tokenize_fn(query[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor(np.array(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = torch.argsort(s.view([1,-1]), dim=1, descending=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법시험에 합격하여 판사로 임용되었고 대법원 재판연구관, 수원지법 부장판사, 사법연수원 교수, 특허법원 부장판사 등을 거쳐 능력을 인정받았다. 2003년 최종영 대법원장의 지명으로 헌법재판소 재판관을 역임하였다.\\\\n\\\\n경제민주화위원회(위원장 장하성이 소액주주들을 대표해 한보철강 부실대출에 책임이 있는 이철수 전 제일은행장 등 임원 4명을 상대로 제기한 손해배상청구소송에서 서울지방법원 민사합의17부는 1998년 7월 24일에 \"한보철강에 부실 대출하여 은행에 막대한 손해를 끼친 점이 인정된다\"며 \"원고가 배상을 청구한 400억원 전액을 은행에 배상하라\"고 하면서 부실 경영인에 대한 최초의 배상 판결을 했다. \\\\n\\\\n2004년 10월 신행정수도의건설을위한특별조치법 위헌 확인 소송에서 9인의 재판관 중 유일하게 각하 견해를 내었다. 소수의견에서 전효숙 재판관은 다수견해의 문제점을 지적하면서 관습헌법 법리를 부정하였다. 전효숙 재판관은 서울대학교 근대법학교육 백주년 기념관에서 열린 강연에서, 국회가 고도의 정치적인 사안을 정치로 풀기보다는 헌법재판소에 무조건 맡겨서 해결하려는 자세는 헌법재판소에게 부담스럽다며 소회를 밝힌 바 있다.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[lis[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [02:16<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_scores = []\n",
    "for q in tqdm(query):\n",
    "    tok_q = tokenize_fn(q)\n",
    "    scores = bm25.get_scores(tok_q)\n",
    "    doc_scores.append(scores)\n",
    "print(\"done!\")\n",
    "#return doc_scores, doc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores = torch.tensor(np.array(doc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_bm25 = torch.argsort(doc_scores, dim=1, descending=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=30\n",
    "context_list = []\n",
    "for index in range(len(ranks_bm25)):\n",
    "    for i in range(k):\n",
    "        context_list.append(contexts[ranks_bm25[index][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9583333333333334]\n"
     ]
    }
   ],
   "source": [
    "context_list = []\n",
    "k= 50\n",
    "for index in range(len(ranks_bm25)):\n",
    "    k_list = []\n",
    "    for i in range(k):\n",
    "        k_list.append(contexts[ranks_bm25[index][i]])\n",
    "    context_list.append(k_list)\n",
    "\n",
    "correct= 0\n",
    "for index in range(len(context_list)):\n",
    "    for ctx_idx in range(len(context_list[0])) :\n",
    "        if ground_truth[index] == context_list[index][ctx_idx]:\n",
    "            correct+=1 \n",
    "print([(correct/len(context_list))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9916666666666667]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct= 0\n",
    "for index in range(len(context_list)):\n",
    "    for ctx_idx in range(len(context_list[0])) :\n",
    "        if ground_truth[index] == context_list[index][ctx_idx]:\n",
    "            correct+=1 \n",
    "print([(correct/len(context_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_context = list(set(context_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5782"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 56737]) 240 56737\n"
     ]
    }
   ],
   "source": [
    "doc_scores = torch.tensor(np.array(doc_scores))\n",
    "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "print(dot_prod_scores.size(),len(doc_scores),len(doc_scores[0]))\n",
    "\n",
    "dpr_score = softmax(dot_prod_scores,dim=1)\n",
    "bm25_score = softmax(doc_scores,dim=1)\n",
    "\n",
    "\n",
    "total_score = []\n",
    "for idx in range(len(query)):\n",
    "    total_score.append((dpr_score[idx]*0.1+bm25_score[idx]).tolist())\n",
    "total_score = torch.tensor(np.array(total_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56737, 240)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_scores[0]), len(doc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 56737]) 240 56737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:50<00:00, 18.44s/it]\n"
     ]
    }
   ],
   "source": [
    "doc_scores = torch.tensor(np.array(doc_scores))\n",
    "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "print(dot_prod_scores.size(),len(doc_scores),len(doc_scores[0]))\n",
    "\n",
    "dpr_score = softmax(dot_prod_scores,dim=1)\n",
    "bm25_score = softmax(doc_scores,dim=1)\n",
    "\n",
    "\n",
    "total_score = []\n",
    "for idx in range(len(query)):\n",
    "    total_score.append((dpr_score[idx]*0.1+bm25_score[idx]).tolist())\n",
    "total_score = torch.tensor(np.array(total_score))\n",
    "\n",
    "\n",
    "k_list = [1,3,5,10,15,20]\n",
    "rate_list=[0.0,0.1,0.2,0.5,1.0,1.1,1.2]\n",
    "\n",
    "score_Dict = {k:[] for k in k_list}\n",
    "\n",
    "\n",
    "for k in tqdm(k_list):\n",
    "    for rate in rate_list:\n",
    "        total_score = []\n",
    "        for idx in range(len(query)):\n",
    "            total_score.append((dpr_score[idx]*rate+bm25_score[idx]).tolist())\n",
    "        total_score = torch.tensor(np.array(total_score))\n",
    "\n",
    "        ranks = torch.argsort(total_score, dim=1, descending=True).squeeze()\n",
    "        context_list = []\n",
    "\n",
    "        for index in range(len(ranks)):\n",
    "            k_list = []\n",
    "            for i in range(k):\n",
    "                k_list.append(contexts[ranks[index][i]])\n",
    "            context_list.append(k_list)\n",
    "\n",
    "        correct= 0\n",
    "        correct_list = []\n",
    "        for index in range(len(context_list)):\n",
    "            for ctx_idx in range(len(context_list[0])) :\n",
    "                if ground_truth[index] == context_list[index][ctx_idx]:\n",
    "                    correct+=1 \n",
    "                    correct_list.append(ctx_idx+1)\n",
    "        score_Dict[k].append([f\"dpr-rate : {rate}\",(correct/len(context_list)),(sum(correct_list)/len(correct_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [['dpr-rate : 0.0', 0.5458333333333333, 1.0],\n",
       "  ['dpr-rate : 0.1', 0.5458333333333333, 1.0],\n",
       "  ['dpr-rate : 0.2', 0.5625, 1.0],\n",
       "  ['dpr-rate : 0.5', 0.5916666666666667, 1.0],\n",
       "  ['dpr-rate : 1.0', 0.6083333333333333, 1.0],\n",
       "  ['dpr-rate : 1.1', 0.6166666666666667, 1.0],\n",
       "  ['dpr-rate : 1.2', 0.625, 1.0]],\n",
       " 3: [['dpr-rate : 0.0', 0.7791666666666667, 1.358288770053476],\n",
       "  ['dpr-rate : 0.1', 0.7916666666666666, 1.3789473684210527],\n",
       "  ['dpr-rate : 0.2', 0.7833333333333333, 1.351063829787234],\n",
       "  ['dpr-rate : 0.5', 0.775, 1.3010752688172043],\n",
       "  ['dpr-rate : 1.0', 0.7833333333333333, 1.2925531914893618],\n",
       "  ['dpr-rate : 1.1', 0.7833333333333333, 1.2819148936170213],\n",
       "  ['dpr-rate : 1.2', 0.775, 1.2526881720430108]],\n",
       " 5: [['dpr-rate : 0.0', 0.8416666666666667, 1.5891089108910892],\n",
       "  ['dpr-rate : 0.1', 0.8583333333333333, 1.6213592233009708],\n",
       "  ['dpr-rate : 0.2', 0.8416666666666667, 1.5643564356435644],\n",
       "  ['dpr-rate : 0.5', 0.8333333333333334, 1.52],\n",
       "  ['dpr-rate : 1.0', 0.8166666666666667, 1.4183673469387754],\n",
       "  ['dpr-rate : 1.1', 0.8166666666666667, 1.403061224489796],\n",
       "  ['dpr-rate : 1.2', 0.8166666666666667, 1.403061224489796]],\n",
       " 10: [['dpr-rate : 0.0', 0.9, 1.9814814814814814],\n",
       "  ['dpr-rate : 0.1', 0.9125, 1.9589041095890412],\n",
       "  ['dpr-rate : 0.2', 0.9083333333333333, 1.963302752293578],\n",
       "  ['dpr-rate : 0.5', 0.9041666666666667, 1.9861751152073732],\n",
       "  ['dpr-rate : 1.0', 0.8875, 1.92018779342723],\n",
       "  ['dpr-rate : 1.1', 0.8833333333333333, 1.8726415094339623],\n",
       "  ['dpr-rate : 1.2', 0.8833333333333333, 1.8820754716981132]],\n",
       " 15: [['dpr-rate : 0.0', 0.9208333333333333, 2.2081447963800906],\n",
       "  ['dpr-rate : 0.1', 0.925, 2.099099099099099],\n",
       "  ['dpr-rate : 0.2', 0.9208333333333333, 2.0950226244343892],\n",
       "  ['dpr-rate : 0.5', 0.9166666666666666, 2.118181818181818],\n",
       "  ['dpr-rate : 1.0', 0.9083333333333333, 2.1559633027522938],\n",
       "  ['dpr-rate : 1.1', 0.9083333333333333, 2.1605504587155964],\n",
       "  ['dpr-rate : 1.2', 0.9083333333333333, 2.1743119266055047]],\n",
       " 20: [['dpr-rate : 0.0', 0.9208333333333333, 2.2081447963800906],\n",
       "  ['dpr-rate : 0.1', 0.9333333333333333, 2.2410714285714284],\n",
       "  ['dpr-rate : 0.2', 0.9291666666666667, 2.233183856502242],\n",
       "  ['dpr-rate : 0.5', 0.9208333333333333, 2.18552036199095],\n",
       "  ['dpr-rate : 1.0', 0.9208333333333333, 2.3574660633484164],\n",
       "  ['dpr-rate : 1.1', 0.9208333333333333, 2.3574660633484164],\n",
       "  ['dpr-rate : 1.2', 0.9208333333333333, 2.3800904977375565]]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "rate=0.2\n",
    "total_score = []\n",
    "for idx in range(len(query)):\n",
    "    total_score.append((dpr_score[idx]*rate+bm25_score[idx]).tolist())\n",
    "total_score = torch.tensor(np.array(total_score))\n",
    "\n",
    "ranks = torch.argsort(total_score, dim=1, descending=True).squeeze()\n",
    "context_list = []\n",
    "\n",
    "for index in range(len(ranks)):\n",
    "    k_list = []\n",
    "    for i in range(k):\n",
    "        k_list.append(contexts[ranks[index][i]])\n",
    "    context_list.append(k_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1,2,3])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct= 0\n",
    "correct_list = []\n",
    "for index in range(len(context_list)):\n",
    "    for ctx_idx in range(len(context_list[0])) :\n",
    "        if ground_truth[index] == context_list[index][ctx_idx]:\n",
    "            correct+=1 \n",
    "            correct_list.append(ctx_idx+1)\n",
    "score_Dict[k].append([(correct/len(context_list)),(sum(correct_list)/len(correct_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_Dict[10] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9125, 1.9223744292237444]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_Dict[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['요크 카운티 동쪽에 처음으로 여객 열차 운행이 시작한 시점은 1868년 토론토 & 니피싱 철도의 설립 인가가 떨어졌을 때였다. 스카버러 남쪽과 코보콘크 마을을 잇는 철도 노선 공사가 시작되었고 1871년 6월에 억스브릿지까지 철도가 완공되었다. 이 노선은 이후 1871년 11월에 캐닝턴까지 연장되었고 1872년 11월에 코보콘크까지 완공되었다. 이 노선의 철로 궤간은 1067mm로 협궤 노선이였다. 목재와 장작 수요가 선로 용량이 넘칠 정도로 많았지만 1870년대에 다른 철도와 마찬가지로 경제적 난황을 이기 못해 수익이 줄어들었다. 투자자들은 수익이 줄어든 이유로 철도가 협궤로 지어져서 다른 표준궤 노선과 연계하여 화물 운송을 할 수 없는 점을 들었다 1881년 7월, 미들랜드 철도가 토론토 & 니피싱 철도를 인수하였고 이 노선은 표준궤로 전환되었다. 미들랜드 철도의 영향은 스카버러에서도 볼 수 있는데 노선 동쪽을 따라 나란히 달리는 미들랜드 애비뉴가 이 철도 회사의 이름을 따서 지어졌다. 1884년, 미들랜드 철도는 그랜드 트렁크 철도에 인수되었고 이는 이후 캐나다 내셔널 철도에 다시 인수되었다. CN은 이 노선을 억스브릿지 선으로 명명하였다 억스브릿지 선을 따라 달리는 여객 철도는 통근객을 위한 열차가 아니였다. 처음에는 론빌에 있는 미들랜드정션역과 토론토를 잇는 열차가 두 대씩 양방향으로 운행했고 한 대는 북동쪽으로 코보콘크까지 운행하였다. 토론토 북동쪽에 있던 시골 마을의 수요는 저조하기만 하였으며 20세기에 들어서서 도로 개량과 자동차 보편화로 쇠락의 길을 걷게 되었다 1955년에는 코보콘크에서 억스브릿지까지 여객 열차 운행이 중단되었으며 30년 뒤 선로 또한 폐선되었다. 1963년에는 억스브릿지까지 이어지는 여객열차 운행이 중단되고 CN 열차는 토론토 유니언역에서 마컴으로 가는 열차를 5시 20분에 딱 한 대 운행하였다. 토론토로 돌아오는 열차는 존재하지 않았다',\n",
       " '이 역이 교통 허브로 거듭나게 된 것은 거의 우연에 가까웠으며 기존에 스카버러 타운 센터에 스카버러 도심을 만들고 싶어했던 설계자들의 바람과는 어긋나게 되었다. 지하철 건설 계획이 진행되면서 토론토 교통국과 시 당국은 다음 지하철 건설에 대해 유보적인 태도를 보였다. 1970년대 중반, 스파다이나 지하철이 지어질 무렵, 지하철 건설 비용이 만만치 않음을 깨달았고 지하철이 필요한 인구 밀도가 높은 지역에는 이미 충분히 지어졌다고 판단하였다. 1970년대 중반에 인구 밀도가 낮은 교외 지역을 어떻게 대중 교통으로 수송할 지 한창 논의가 이어졌다. 토론토 교통국은 전용 선로를 따라 달리는 노면 전차 노선을 선호했지만 온타리오 주는 그 당시 최첨단 기술을 선호하여 주 공기업인 도시 개발 교통 공사를 통해 선형 유도 자기 부상 모터를 사용한 철도를 추구하였다. 교통국과 시 당국은 그 당시 블루어-댄포스 선의 종착역이였던 워든역과 스카버러 타운 센터를 고속 노면 전차 체계로 스카버러 북동쪽 끝까지 이을 계획이였다. 하지만 스카버러는 지하철 연장을 추구하였다. 이를 두고 시 당국은 블루어-댄포스 선을 워든역에서 북동쪽으로 한 정거장 연장하고, 케네디역에서 스카버러 타운 센터까지 경전철로 연장하고자 하였다 한편 이토비코도 이즐링턴역에서 서쪽으로 키플링까지 한 정거장 연장하기로 하였다. 이 연장에 따라 워든역과 이즐링턴역으로 진입하는 버스의 혼잡을 줄이고 새로운 환승 주차장 공간은 물론 기존 종착역의 주차 문제도 완화할 수 있을 것으로 보였다. 1970년대 중반 지하철 연장 예산은 케네디 동부 연장이 7140만 달러, 키플링 서부 연장은 3860달러로 총 1억 1천만 달러로 추산되었다',\n",
       " '( ) |개업일 = 1985년 3월 22일 |폐지일 = |관할 = 토론토 교통국 |승강장 = 2면 2선 (상대식) |노선1 = 3호선 스카버러 |영업거리1 = |전역1 = 매코원 |전거리1 = |후역1 = 미들랜드 |후거리1 = |비고 = |주석 = }} 스카버러센터역(Scarborough Centre Station)은 토론토 지하철 3호선 스카버러의 정차역으로 종착역인 매코원역에서 한 정거장 떨어져있으며 케네디역 다음으로 RT에서 승객 수가 가장 많은 역이다. 엘즈미어 로드 북쪽에 브림리와 매코원 로드 사이에 있으며 401번 고속도로 바로 남쪽에 있다. 이 역은 스카버러를 지나는 TTC 버스 노선이 다수 정차하며 역 맞은 편의 스카버러센터 버스 터미널에는 GO 트랜싯, 메가버스, 그레이하운드 캐나다를 포함한 광역 및 시외버스가 다수 정차한다.',\n",
       " '블루어-댄포스선의 스카버러 타운 센터 연장에 따른 나머지 구간의 공백을 메우기 위해 토론토시는 5호선 에글린턴선을 스카버러를 향해 계속 동쪽으로 토론토 대학교 스카버러 캠퍼스와 맬번 타운 센터까지 연장하는 방안을 추진하고 있다. 총 연장 12km의 동부 연장 구간은 에글린턴과 길드우드 통근열차역으로 갈아탈 수 있게 되며 에글린턴이스트, 스카버러정션, 모닝사이드, 스카버러빌리지, 웨스트힐과 같은 저소득층 및 대중교통 의존도가 높은 지역을 지나가게 된다. 이 계획에 따르면 케네디역 동쪽으로 18개 정거장을 신설하고 하루 평균 43,400명이 이용할 것으로 예상되며, 이는 4호선 셰퍼드선 승객 수와 비슷한 수치이다. 동부 연장은 트랜싯 시티에서 거론되었던 스카버러 맬번 경전철 (Scarborough Malvern LRT)과 선형이 같은데, 2009년에 토론토 시의회와 온타리오 주정부에서 승인받았음에도 불구하고 2010년에 롭 포드 시장이 취임하면서 취소되었다. 2016년 초반, 스카버러 맬번 경전철 계획안이 \"크로스타운 이스트\" (Crosstown East)라는 이름으로 수면에 다시 올랐고 2017년에는 \"에글린턴 이스트\" (Eglinton East)로 이름이 바뀌었다. 2017년 11월, 시의회에서는 에글린턴 경전철을 UTSC 캠퍼스에서 여섯 정거장 늘려 맬번 타운 센터까지 연장하는 방안을 발표하였다. 맬번 연장 구간은 4.2km에서 4.7km정도 되며 UTSC에서 팬앰 드라이브, 셰퍼드/모닝사이드, 브레니언 웨이, 뮤리슨 블루버드, 셰퍼드/닐슨, 윅슨 트레일과 종착역인 맬번 타운센터 등 총 여섯 정거장이다 2018년 5월 23일, 토론토 시의회는 에글린턴 경전철을 맬번으로 연장하기로 하였지만 별다른 예산 지원이 없어 계획은 여전히 불투명하였다. 2019년 토론토시 계획안의 따르면 킹스턴 로드와 모닝사이드까지는 14억, 토론토 대학교 스카버러 캠퍼스까지는 16억, 맬번까지는 20억 달러의 예산이 들어가는 것으로 파악되었다. 2019년 4월, 포드 주지사는 에글린턴 서부 연장, 블루어-댄포스선 스카버러 연장, 영 지하철 연장 및 온타리오선에 예산을 지원하였으나 에글린턴 동부 연장은 포함되지 않았다. 2020년 4월 현재 초기 계획 단계는 마무리 지은 상태이고 토론토시가 맬번 타운 센터까지 연장하는 계획을 본격적으로 수립하기 위해 메트로링스와 협의하고 있다.',\n",
       " '1950년 10월 1일 슬루센-회카렝엔 구간이 개통되었다. 1957년 회토리에트-슬루센 사이가 개통되었고, 그뢰나 선의 떨어진 두 부분이 연결되었다. 현재의 노선은 대부분 1960년이 되기 전에 개통되었다. 1971년과 1994년 파르스타 스트란드 역과 스카르프넥 역이 개통되었고, 스카르프넥 역은 스톡홀름 지하철에서 100번째로 개통된 역이다. 도시 철도가 개통되기 전 일부 노선은 지하 노면 전차 노선으로 개업하였다. * 1933년 쇠데르 터널 * 1934년 트라네베리 교 * 1946년 스칸스툴 교. 이후 도시 철도 노선으로 편입되었다. * 1944년 엥뷔 선(알비크-오셰스호브) * 1930년대 외르뷔 선(글로벤-스투레뷔), 이후 평면 교차가 해소되었다. 도시 철도와 노면 전차 노선의 차이는 전차선의 위치(노면 전차는 가공 전차선, 도시 철도는 차량 하부), 평면 교차 여부이다.',\n",
       " '말뫼와 코펜하겐을 잇는 외레순 대교 건설은 1991년부터 계획되었다. 1995년 스베다브 AB(Svensk-Danska Broförbindelsen)에서 기초 조사를 실시하였다. 1998년 시티 터널을 짓기로 계획하였고, 2005년 3월 착공하였다. 공식적인 완공일은 2010년 12월 4일이고, 열차 운행 시작은 12월 12일이다. 터널의 주 역할은 말뫼 센트랄 역을 종착역에서 중간역으로 변경하여 여객 열차를 더 많이 투입하는 것이며, 말뫼의 신 도심에 역을 추가로 건설하고, 기존의 콘티넨탈 선을 화물용으로 전환하는 것이다. 트리앙겔른 역은 말뫼 도심의 남부에 건설되어 이 곳으로 이동하는 시간을 단축하였다. 휠리에 역은 말뫼 남부에 건설되었다. 말뫼 센트랄 역은 추가 승강장이 지하에 건설되었고, 열차의 방향을 돌리지 않아도 되어서 운행 시간을 감소시켰다.',\n",
       " \"주빌리 선 스탠모어 지선은 원래 메트로폴리탄 철도에서 건설되었으며 1939년 베이컬루 선의 스탠모어 지선으로 지정되었다. 1979년 5월 1일 주빌리 선으로 이관되었다. 베이커가의 베이컬루 본선과 연결되었다. * 스탠모어 / Stanmore * 캐논스 파크 / Canons Park * 퀸즈베리 / Queensbury * 킹즈베리 / Kingsbury * 웸블리 파크 / Wembley Park * 니즈던 / Neasden * 돌리스 힐 / Dollis Hill * 윌스던 그린 / Willesden Green * 킬번 / Kilburn * 웨스트 햄스테드 / West Hampstead * 핀츨리 로드 / Finchley Road * 스위스 코티지 / Swiss Cottage * 세인트 존스 우드 / St. John's Wood * 베이커 스트리트 / Baker Street\",\n",
       " '메트로폴리탄 철도(해로 & 옥스브리지 철도)는 해로온더힐과 옥스브리지 사이의 선로를 건설했으며 1904년 7월 4일에 운행을 시작했다. 처음에는 뤼슬립 역이 유일한 중간 정거장이었다. 처음에는 증기 열차로 운행했지만 다음 달에는 선로 전철화가 완료되었고, 전기 열차는 1905년 1월 1일에 운행하기 시작했다. 향후 20년 동안 미들섹스 북부 지역의 점진적 개발은 새로운 주거 지역의 성장을 장려하기 위해 옥스브리지 지선을 따라 점차적으로 추가 지선을 개방하게 되었다. 이스트코트 역은 1906년 5월 26일 이스트코트 Halt(Eastcote Halt)란 이름으로 개업했다. 1910년 3월 1일 사우스 해로 발 디스트릭트 선이 레이너스 레인의 메트로폴리탄 철도와 연결 및 연장 됨으로써 디스트릭트 선 열차가 레이너스 레인 역과 옥스브리지 사이의 역을 운행할 수 있게 되었다. 1933년 10월 23일에 디스트릭트 선 운행이 피카딜리 선 열차로 대체되었다. 재건된 역사는 1937년과 1939년 사이에 찰스 홀든(Charles Holden)이 디자인했다. 이 건물은 이 기간에 건축 된 새로운 역의 전형적인 평평한 철근 콘크리트 지붕과 기하학적 모양으로 덮힌 큰 큐브 모양의 벽돌과 유리 대합실을 특징으로 한다. 역 건물과 승강장은 2급으로 표시된다. 역은 이스트코트 교외에 둘러싸여 있다. 올드이스트코트(Old Eastcote)로 알려진 원래의 중심지가 약간의 거리에 있다. 인근의 캐빈디쉬 파빌리온은 20세기 초반에 인기있는 여행지였다.',\n",
       " '이 역은 디스트릭트 철도(DR, 현재의 디스트릭트 선)에서 얼스 코트(Earl\\'s Court)~해머스미스(Hammersmit)간 연장선 개통과 함께 1874년 9월 9일에 개업했으며, 당시 명칭은 \\'노스 엔드(풀럼)/North End (Fulham)\\'이었다. 당시 서쪽 다음역은 해머스미스였다. - 배런즈 코트(Barons Court) 역은 1905년까지 열리지 않았다. 1877년에 현재의 웨스트 켄징턴으로 개명되었다. 1878년 5월 5일, 미들랜드 철도(Midland Railway)는 세인트판크라스 역에서 크리클우드(Cricklewood)와 사우스 액트(South Acton)를 통해 얼스 코트 역까지 이르는 \"초외부 순환선(Super Outer Circle)\"로 알려진 순환 운행을 시작했다. 이는 현재 NLR의 현재 사용되지 않는 연결과 런던 & 사우스 웨스턴 철도(London South Western Railway)의 리치먼드 지선(현재는 디스트릭트 선의 일부)을 통해 운영되었다. 이 서비스는 성공하지 못했으며 1880년 9월 30일에 폐지되었다. 입구 건물은 1927년에 재건되었다. 찰스 홀든(Charles Holden)의 설계는 1926년에 개통한 모던 연장선을 위해 사용된 것과 비슷한 재료와 마감재를 사용한다.',\n",
       " '캠버웰과 덴마크 힐로 가는 노선의 남쪽 끝에 있는 연장 구간은 London Electric Metropolitan District and Central London Railway Companies (Works) Act, 1931의 일부로 1931년에 제안되어 승인되었다. 1937년 4월 제안 된 연장 구간의 비용은 5,000,000 파운드(오늘날 기준 약 3억 2천만 파운드) 였고, 런던 승객 운송위원회는 재료 가격 상승으로 이사회 재정이 개선 될 때까지 연장이 연기되었다고 발표했다. 엘리펀트 & 캐슬 역의 남쪽 방향 연장과 별개로 제2차 세계 대전 이전에는 연장 작업이 없었지만 1940년 특별법 (연장법)(Special Enactments (Extension of Time) Act, 1940)에 따라 1947년에 정부에 의해 권한이 갱신되었다. 캠버웰까지의 예상 연장은 1949년 지하지도에서 보였으나 더 이상의 연구는 수행되지 않았다. 워릭 애비뉴 역의 기관사는 캠버웰을 1990년대까지 목적지로 간주했다.']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "학습 : train -> 검증 : valid question을 전체 wiki에서 뽑기 \n",
    "DPR은 0.2쯤둬야 약간 오르고 나머지는 오히려 낮추었음\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
