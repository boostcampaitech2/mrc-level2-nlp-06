{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Retriver 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dense_retrieval import DenseRetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from typing import List, Tuple, NoReturn, Any, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "\n",
    "from transformers import AutoTokenizer, BertModel, BertPreTrainedModel, AdamW, TrainingArguments, get_linear_schedule_with_warmup\n",
    "from datasets import Dataset, load_from_disk, concatenate_datasets\n",
    "\n",
    "from retrieval import SparseRetrieval, timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../data/train_dataset/train/cache-fbc57aa6e699fb0c.arrow\n",
      "Loading cached processed dataset at ../data/train_dataset/validation/cache-d2fba0c42123b1d6.arrow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "\n",
    "data_path  = \"../data/\"\n",
    "dataset_path = \"../data/train_dataset\"\n",
    "context_path = \"wikipedia_documents.json\"\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "\n",
    "org_dataset = load_from_disk(dataset_path)\n",
    "full_ds = concatenate_datasets([\n",
    "        org_dataset[\"train\"].flatten_indices(),\n",
    "        org_dataset[\"validation\"].flatten_indices(),\n",
    "    ])\n",
    "\n",
    "with open(os.path.join(data_path, context_path), \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "contexts = list(dict.fromkeys([v[\"text\"] for v in wiki.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(org_dataset['train'])\n",
    "#df_train = df_train[['document_id','title','answers','question','context', 'id','__index_level_0__']]\n",
    "df_train = df_train[['answers']]\n",
    "df_train.to_csv('./data/train_answers.csv')\n",
    "\n",
    "df_valid = pd.DataFrame(org_dataset['validation'])\n",
    "#df_valid = df_valid[['document_id','title','answers','question','context', 'id','__index_level_0__']]\n",
    "df_valid = df_valid[['answers']]\n",
    "df_valid.to_csv('./data/valid_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56737"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[s for s in contexts if org_dataset[\"validation\"][0]['context'][0:5] in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,use_fast=False,)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of unique wiki contexts : 56737\n",
      "Embedding bm25 pickle load.\n",
      "make_train_data...\n"
     ]
    }
   ],
   "source": [
    "dense_retriever = DenseRetrieval(tokenize_fn=tokenizer.tokenize, data_path = data_path, \n",
    "                                context_path = context_path, dataset_path=dataset_path, \n",
    "                                tokenizer=tokenizer, train_data=org_dataset[\"train\"], is_bm25=True)\n",
    "## 학습과정 ##\n",
    "train_dataset = dense_retriever.make_train_data(tokenizer)\n",
    "# dense_retriever.init_model(model_checkpoint)\n",
    "# dense_retriever.train(args, train_dataset)\n",
    "\n",
    "## 추론과정 ##\n",
    "# dense_retriever.load_model(model_checkpoint, \"outputs/p_encoder_3.pt\", \"outputs/q_encoder_3.pt\")\n",
    "# dense_retriever.get_dense_embedding()\n",
    "# df = dense_retriever.retrieve(full_ds[0]['question'], topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dense_embedding3.bin\", \"rb\") as f:\n",
    "    dense_retriever.dense_p_embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/dense_embedding.bin\", \"wb\") as f:\n",
    "    pickle.dump(dense_retriever.dense_p_embedding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever.dense_p_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 실험 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever.get_relevant_doc(org_dataset[\"train\"][\"question\"][0], k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_retriever = dense_retriever.retrieve(org_dataset[\"validation\"], topk=5)\n",
    "result_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    df = dense_retriever.retrieve(org_dataset['validation'][i]['question'], topk=3)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK_list = [1,10,20,50]\n",
    "result = dense_retriever.topk_experiment(topK_list, org_dataset['validation'])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
