{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from utils.preprocess import prepare_datasets_with_setting\n",
    "from typing import List, Callable, NoReturn, NewType, Any\n",
    "import dataclasses\n",
    "from datasets import load_metric, load_from_disk, Dataset, DatasetDict\n",
    "from transformers import AutoConfig, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import torch\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "from utils.trainer_qa import QuestionAnsweringTrainer\n",
    "\n",
    "from arguments import (\n",
    "    ModelArguments,\n",
    "    DataTrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = load_from_disk(\"../data/train_dataset\")\n",
    "testsets = load_from_disk(\"../data/test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/wikipedia_documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            wiki = json.load(f)\n",
    "\n",
    "contexts = list(\n",
    "            dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenize_fn = tokenizer.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b2ccea01e148088d87d94308c593be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenized_corpus = []\n",
    "p_embs = []\n",
    "for p in tqdm(contexts):\n",
    "    tokenized_corpus.append(tokenize_fn(p, padding=\"max_length\", truncation=True, return_tensors='pt'))\n",
    "bm25 = MyBm25(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_embedding(bm25,contexts, tokenize_fn,data_path =\"../\",k1=1.5, b=0.75, epsilon=0.25) -> NoReturn:\n",
    "\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        Passage Embedding을 만들고\n",
    "        TFIDF와 Embedding을 pickle로 저장합니다.\n",
    "        만약 미리 저장된 파일이 있으면 저장된 pickle을 불러옵니다.\n",
    "    \"\"\"\n",
    "    bm25_name = f\"bm25.bin\"\n",
    "    bm25_path = os.path.join(data_path, bm25_name)\n",
    "    if os.path.isfile(bm25_path):\n",
    "        with open(bm25_path, \"rb\") as file:\n",
    "            bm25 = pickle.load(file)\n",
    "        print(\"Embedding bm25 pickle load.\")\n",
    "    else:\n",
    "        print(\"Building bm25... It may take 1 minute and 30 seconds...\")\n",
    "        # bm25 must tokenizer first \n",
    "        # because it runs pool inside and this cuases unexpected result.\n",
    "        tokenized_corpus = []\n",
    "        for c in contexts:\n",
    "            tokenized_corpus.append(tokenize_fn(c))\n",
    "        bm25 = MyBm25(tokenized_corpus, k1 = k1, b = b, epsilon=epsilon)\n",
    "        with open(bm25_path, \"wb\") as file:\n",
    "            pickle.dump(bm25, file)\n",
    "        print(\"bm25 pickle saved.\")\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building bm25... It may take 1 minute and 30 seconds...\n",
      "bm25 pickle saved.\n"
     ]
    }
   ],
   "source": [
    "bm25 = get_sparse_embedding(bm25,contexts,tokenize_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=1.5\n",
    "b=0.75\n",
    "epsilon=0.25\n",
    "topk=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding bm25 pickle load.\n"
     ]
    }
   ],
   "source": [
    "bm25_name = f\"bm25.bin\"\n",
    "bm25_path = os.path.join(data_path, bm25_name)\n",
    "if os.path.isfile(bm25_path):\n",
    "    with open(bm25_path, \"rb\") as file:\n",
    "        bm25 = pickle.load(file)\n",
    "    print(\"Embedding bm25 pickle load.\")\n",
    "else:\n",
    "    print(\"Building bm25... It may take 1 minute and 30 seconds...\")\n",
    "    # bm25 must tokenizer first \n",
    "    # because it runs pool inside and this cuases unexpected result.\n",
    "    tokenized_corpus = []\n",
    "    for c in contexts:\n",
    "        tokenized_corpus.append(tokenize_fn(c))\n",
    "    bm25 = MyBm25(tokenized_corpus, k1 = k1, b = b, epsilon=epsilon)\n",
    "    with open(bm25_path, \"wb\") as file:\n",
    "        pickle.dump(bm25, file)\n",
    "    print(\"bm25 pickle saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'처음으로 부실 경영인에 대한 보상 선고를 받은 회사는?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['validation']['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(bm25, query, documents, n=20):\n",
    "    assert bm25.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
    "\n",
    "    scores = bm25.get_scores(query)\n",
    "\n",
    "    top_n_idx = np.argsort(scores)[::-1][:n]\n",
    "    doc_score = scores[top_n_idx]\n",
    "        \n",
    "    return doc_score, top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain = datasets['train']['question'][:-1000]\n",
    "addtext = datasets['train']['question'][-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = addtext + datasets['validation']['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = datasets['train']['context'][-1000:] + datasets['validation']['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = testsets['validation']['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 1240)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries), len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores = []\n",
    "doc_indices = []\n",
    "class Retriever:\n",
    "    def __init__(self, tf,bm25,contexts, queries, k =20):\n",
    "        self.tokenize_fn = tf\n",
    "        self.bm25 = bm25\n",
    "        self.contexts = contexts\n",
    "        self.k = k\n",
    "    def get_relevant_doc(self, query: str, k: Optional[int] = 1) -> Tuple[List, List]:\n",
    "        tok_q = self.tokenize_fn(query)\n",
    "        doc_score, doc_indices = self.bm25.get_top_n(tok_q, self.contexts, n = k)\n",
    "        return doc_score, doc_indices\n",
    "# parallel search\n",
    "# 하나로 쪼개서 안에 들어가서 각각 토크나이즈를 한다.\n",
    "retriever = Retriever(tokenize_fn, bm25, contexts, queries, topk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval import MyBm25\n",
    "def get_sparse_embedding(bm25,contexts, tokenize_fn,data_path =\"../\",k1=1.5, b=0.75, epsilon=0.25) -> NoReturn:\n",
    "\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        Passage Embedding을 만들고\n",
    "        TFIDF와 Embedding을 pickle로 저장합니다.\n",
    "        만약 미리 저장된 파일이 있으면 저장된 pickle을 불러옵니다.\n",
    "    \"\"\"\n",
    "    bm25_name = f\"bm25.bin\"\n",
    "    bm25_path = os.path.join(data_path, bm25_name)\n",
    "    if os.path.isfile(bm25_path):\n",
    "        with open(bm25_path, \"rb\") as file:\n",
    "            bm25 = pickle.load(file)\n",
    "        print(\"Embedding bm25 pickle load.\")\n",
    "    else:\n",
    "        print(\"Building bm25... It may take 1 minute and 30 seconds...\")\n",
    "        # bm25 must tokenizer first \n",
    "        # because it runs pool inside and this cuases unexpected result.\n",
    "        tokenized_corpus = []\n",
    "        for c in contexts:\n",
    "            tokenized_corpus.append(tokenize_fn(c))\n",
    "        bm25 = MyBm25(tokenized_corpus, k1 = k1, b = b, epsilon=epsilon)\n",
    "        with open(bm25_path, \"wb\") as file:\n",
    "            pickle.dump(bm25, file)\n",
    "        print(\"bm25 pickle saved.\")\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = MyBm25(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building bm25... It may take 1 minute and 30 seconds...\n",
      "bm25 pickle saved.\n"
     ]
    }
   ],
   "source": [
    "bm25 = MyBm25(tokenized_corpus)\n",
    "se = get_sparse_embedding(bm25,contexts,tokenize_fn)\n",
    "bm25 = se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = datasets['train']['question'] + datasets['validation']['question'] + testsets['validation']['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a645742504047f19389c51c6d5c13d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "doc_scores = []\n",
    "for q in tqdm(queries):\n",
    "    tok_q = tokenize_fn(q)\n",
    "    scores = bm25.get_scores(tok_q)\n",
    "    doc_scores.append(scores)\n",
    "print(\"done!\")\n",
    "#return doc_scores, doc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores = torch.tensor(np.array(doc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = torch.argsort(doc_scores, dim=1, descending=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topk = 100\n",
    "\n",
    "context_list = []\n",
    "\n",
    "for index in range(len(ranks)):\n",
    "    for i in range(topk):\n",
    "        context_list.append(contexts[ranks[index][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'갈리프레이 (Gallifrey)는 영국의 SF 텔레비전 드라마 《닥터 후》에서 등장하는 행성이다. 드라마의 주인공인 닥터와 마스터를 비롯한 지금까지 등장한 모든 타임 로드의 고향이다. 카스터보로스 성단 내에서    \"은하 중심에서 은하좌표로 10-0-11-0-0 하고도 0-2 지점\"에 위치해 있으며   쌍성계를 이루고 있다. \\n\\n닥터의 고향 행성은 드라마 방영 초반에는 밝혀지지 않다가, 2대 닥터 에피소드인 The War Games (1969)에서 닥터의 고향 행성이 처음으로 등장했다.  닥터의 행성을 \\'갈리프레이\\'라는 이름으로 확실히 구분하게 된 것은 3대 닥터 시절의 The Time Warrior (1973–74)에 이르러서였다.  갈리프레이가 언제 처음 나타났는지에 대해서는 명확히 밝혀진 바가 없다. 행성 자체가 시간 여행을 통해 접근하는 경우가 많은 만큼, 갈리프레이에서의 \\'지금\\'은 지구에서는 과거나 미래나 어느 때든지 상대적으로 존재할 수 있다.\\n\\n2005년 드라마가 부활하면서 갈리프레이에 대한 설정도 옛 시즌의 설정을 조금씩 채워나가고 있다. 시즌 1 에피소드 \"The End of the World\"에서 9대 닥터는 갈리프레이의 모습을 \"그 날이 오기 전까진\" \"바위와 먼지\"밖에 없었다고 말하고, 이후로는 시간 전쟁이 일어나면서 50억년 뒤의 지구처럼 갈리프레이도 타임 로드와 함께 모두 \"불타 버렸다\"고 언급한다.  이후 갈리프레이는 등장하지 않다가 2006년 크리스마스 스페셜 \"The Runaway Bride\"에서 다시 언급된다.  시즌 3의 \"The Sound of Drums\"에서는 회상 장면 중에 처음 그 풍경이 묘사되며  The End of Time (2009–10)에서는 줄거리의 주요 무대로까지 등장한다.  It appeared briefly in the 시즌 7 마지막화 \"The Name of the Doctor\"에서도 짧게 등장하며, 1대 닥터와 수잔이 타디스를 훔치는 순간까지 등장한다.  \"The Day of the Doctor\" (2013)의 막바지에서는 갈리프레이가 사실은 닥터가 원래 알고 있던 대로 멸망하지 않고 \"(대)시간 전쟁\"에서 살아남았으나, 시간이 정지된 채 또다른 차원 속에 갇히게 되었다는 것이 밝혀진다.  이후 12대 닥터에 이르러 \"Hell Bent\" (2015) 바로 이전의 어느 시점에 원래 우주로 돌아오게 되었다.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26825"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = list(set(context_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_preprocess(data_dict):\n",
    "            text = data_dict[\"text\"]\n",
    "            text = re.sub(r'\\n', ' ', text)\n",
    "            text = re.sub(r\"\\\\n\", \" \", text)\n",
    "            text = re.sub(r'\\\\n\\\\n', ' ', text)\n",
    "            text = re.sub(r'\\n\\n', \" \", text)\n",
    "            text = re.sub(r\"\\s+\", \" \", text)\n",
    "            text = re.sub(r'#', ' ', text)\n",
    "            data_dict[\"text\"] = text\n",
    "            return data_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c, valid_c = context_list[:1000], context_list[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_train = []\n",
    "for c in train_c:\n",
    "    txt = ' '.join((map(str, c)))\n",
    "    added_train.append(txt)\n",
    "\n",
    "added_valid = []\n",
    "for c in valid_c:\n",
    "    txt = ' '.join((map(str, c)))\n",
    "    added_valid.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets['train']['answers'][-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Dataset.from_dict({'answers':datasets['train']['answers'][-1000:], \n",
    "                    'context':added_train,\n",
    "                    'id' : datasets['train']['id'][-1000:],\n",
    "                    'question':datasets['train']['question'][-1000:]})\n",
    "\n",
    "validdata = Dataset.from_dict({'answers':datasets['validation']['answers'], \n",
    "                    'context':added_valid,\n",
    "                    'id' : datasets['validation']['id'],\n",
    "                    'question':datasets['validation']['question']})\n",
    "\n",
    "top5 = DatasetDict({\"train\":traindata, \"validation\":validdata})\n",
    "\n",
    "top5.save_to_disk(\"../data/added_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Dataset.from_dict({'answers':datasets['train']['answers'][:-1000], \n",
    "                    'context':datasets['train']['context'][:-1000],\n",
    "                    'id' : datasets['train']['id'][:-1000],\n",
    "                    'question':datasets['train']['question'][:-1000]})\n",
    "\n",
    "validdata = Dataset.from_dict({'answers':datasets['validation']['answers'], \n",
    "                    'context':datasets['validation']['context'],\n",
    "                    'id' : datasets['validation']['id'],\n",
    "                    'question':datasets['validation']['question']})\n",
    "\n",
    "top5 = DatasetDict({\"train\":traindata, \"validation\":validdata})\n",
    "\n",
    "top5.save_to_disk(\"../data/new_train_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = Dataset.from_dict({'text':valid_c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt.save_to_disk(\"../data/valid_wiki/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_from_disk(\"../data/valid_wiki/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 43979\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2952, 240)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindata), len(validdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./new_wiki.txt', 'w') as f:\n",
    "    for item in context_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = datasets['train']['context'] + datasets['validation']['context'] + context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43985"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = list(set(cs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = a['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = datasets['validation']['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = datasets['validation']['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval import MyBm25\n",
    "def get_sparse_embedding(bm25,contexts, tokenize_fn,data_path =\"../\",k1=1.5, b=0.75, epsilon=0.25) -> NoReturn:\n",
    "\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        Passage Embedding을 만들고\n",
    "        TFIDF와 Embedding을 pickle로 저장합니다.\n",
    "        만약 미리 저장된 파일이 있으면 저장된 pickle을 불러옵니다.\n",
    "    \"\"\"\n",
    "    bm25_name = f\"bm25.bin\"\n",
    "    bm25_path = os.path.join(data_path, bm25_name)\n",
    "    if os.path.isfile(bm25_path):\n",
    "        with open(bm25_path, \"rb\") as file:\n",
    "            bm25 = pickle.load(file)\n",
    "        print(\"Embedding bm25 pickle load.\")\n",
    "    else:\n",
    "        print(\"Building bm25... It may take 1 minute and 30 seconds...\")\n",
    "        # bm25 must tokenizer first \n",
    "        # because it runs pool inside and this cuases unexpected result.\n",
    "        tokenized_corpus = []\n",
    "        for c in contexts:\n",
    "            tokenized_corpus.append(tokenize_fn(c))\n",
    "        bm25 = MyBm25(tokenized_corpus, k1 = k1, b = b, epsilon=epsilon)\n",
    "        with open(bm25_path, \"wb\") as file:\n",
    "            pickle.dump(bm25, file)\n",
    "        print(\"bm25 pickle saved.\")\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14941/14941 [00:28<00:00, 530.42it/s]\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenize_fn = tokenizer.tokenize\n",
    "tokenized_corpus = []\n",
    "p_embs = []\n",
    "for p in tqdm(contexts):\n",
    "    tokenized_corpus.append(tokenize_fn(p, padding=\"max_length\", truncation=True, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding bm25 pickle load.\n"
     ]
    }
   ],
   "source": [
    "bm25 = MyBm25(tokenized_corpus)\n",
    "se = get_sparse_embedding(bm25,contexts,tokenize_fn)\n",
    "bm25 = se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996c0915bb5a48b89897875c7a75a979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "doc_scores = []\n",
    "for q in tqdm(queries):\n",
    "    tok_q = tokenize_fn(q)\n",
    "    scores = bm25.get_scores(tok_q)\n",
    "    doc_scores.append(scores)\n",
    "print(\"done!\")\n",
    "#return doc_scores, doc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer,BertPreTrainedModel,BertModel\n",
    "import numpy as np\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "\n",
    "class BertEncoder(BertPreTrainedModel):\n",
    "  def __init__(self, config):\n",
    "    super(BertEncoder, self).__init__(config)\n",
    "\n",
    "    self.bert = BertModel(config)\n",
    "    self.init_weights()\n",
    "      \n",
    "  def forward(self, input_ids, \n",
    "              attention_mask=None, token_type_ids=None): \n",
    "  \n",
    "      outputs = self.bert(input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids)\n",
    "      \n",
    "      pooled_output = outputs[1]\n",
    "\n",
    "      return pooled_output\n",
    "\n",
    "\n",
    "# load pre-trained model on cuda (if available)\n",
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_encoder.load_state_dict(torch.load(\"../dpr/neg20_p_encoder_14.pt\"))\n",
    "q_encoder.load_state_dict(torch.load(\"../dpr/neg20_q_encoder_14.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  p_encoder.cuda()\n",
    "  q_encoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_fn = tokenizer.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14551a4eae29468a83e3f463de7462ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  p_encoder.eval()\n",
    "  tokenized_corpus = []\n",
    "  p_embs = []\n",
    "  for p in tqdm(contexts):\n",
    "    p_t = tokenizer(p, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "    p_emb = p_encoder(**p_t).to('cpu').numpy()\n",
    "    p_embs.append(p_emb)\n",
    "    tokenized_corpus.append(tokenize_fn(p, padding=\"max_length\", truncation=True, return_tensors='pt'))\n",
    "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14941, 768]) torch.Size([240, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  q_encoder.eval()\n",
    "  q_seqs_val = tokenizer(queries, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda')\n",
    "  q_emb = q_encoder(**q_seqs_val).to('cpu')  #(num_query, emb_dim)\n",
    "\n",
    "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
    "\n",
    "print(p_embs.size(), q_emb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 14941]) 240 14941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0381fae8fea54c329a5d9366eb779358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_scores = torch.tensor(np.array(doc_scores))\n",
    "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "print(dot_prod_scores.size(),len(doc_scores),len(doc_scores[0]))\n",
    "\n",
    "dpr_score = softmax(dot_prod_scores,dim=1)\n",
    "bm25_score = softmax(doc_scores,dim=1)\n",
    "\n",
    "\n",
    "total_score = []\n",
    "for idx in range(len(queries)):\n",
    "    total_score.append((dpr_score[idx]*0.1+bm25_score[idx]).tolist())\n",
    "total_score = torch.tensor(np.array(total_score))\n",
    "\n",
    "\n",
    "k_list = [1,10,15,20,30]\n",
    "rate_list=[0.0,0.1,0.2,0.5]\n",
    "\n",
    "score_Dict = {k:[] for k in k_list}\n",
    "\n",
    "\n",
    "for k in tqdm(k_list):\n",
    "    for rate in rate_list:\n",
    "        total_score = []\n",
    "        for idx in range(len(queries)):\n",
    "            total_score.append((dpr_score[idx]*rate+bm25_score[idx]).tolist())\n",
    "        total_score = torch.tensor(np.array(total_score))\n",
    "\n",
    "        ranks = torch.argsort(total_score, dim=1, descending=True).squeeze()\n",
    "        context_list = []\n",
    "\n",
    "        for index in range(len(ranks)):\n",
    "            k_list = []\n",
    "            for i in range(k):\n",
    "                k_list.append(contexts[ranks[index][i]])\n",
    "            context_list.append(k_list)\n",
    "\n",
    "        correct= 0\n",
    "        correct_list = []\n",
    "        for index in range(len(context_list)):\n",
    "            for ctx_idx in range(len(context_list[0])) :\n",
    "                if ground_truth[index] == context_list[index][ctx_idx]:\n",
    "                    correct+=1 \n",
    "                    correct_list.append(ctx_idx+1)\n",
    "        score_Dict[k].append([f\"dpr-rate : {rate}\",(correct/len(context_list)),(sum(correct_list)/len(correct_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [['dpr-rate : 0.0', 0.55, 1.0],\n",
       "  ['dpr-rate : 0.1', 0.5625, 1.0],\n",
       "  ['dpr-rate : 0.2', 0.575, 1.0],\n",
       "  ['dpr-rate : 0.5', 0.6083333333333333, 1.0]],\n",
       " 10: [['dpr-rate : 0.0', 0.9041666666666667, 1.9262672811059909],\n",
       "  ['dpr-rate : 0.1', 0.925, 1.9684684684684686],\n",
       "  ['dpr-rate : 0.2', 0.9291666666666667, 1.9955156950672646],\n",
       "  ['dpr-rate : 0.5', 0.9125, 1.8447488584474885]],\n",
       " 15: [['dpr-rate : 0.0', 0.9083333333333333, 1.981651376146789],\n",
       "  ['dpr-rate : 0.1', 0.9333333333333333, 2.049107142857143],\n",
       "  ['dpr-rate : 0.2', 0.9333333333333333, 2.0401785714285716],\n",
       "  ['dpr-rate : 0.5', 0.925, 1.9864864864864864]],\n",
       " 20: [['dpr-rate : 0.0', 0.9166666666666666, 2.1227272727272726],\n",
       "  ['dpr-rate : 0.1', 0.9375, 2.1244444444444444],\n",
       "  ['dpr-rate : 0.2', 0.9375, 2.12],\n",
       "  ['dpr-rate : 0.5', 0.9375, 2.1911111111111112]],\n",
       " 30: [['dpr-rate : 0.0', 0.9541666666666667, 3.021834061135371],\n",
       "  ['dpr-rate : 0.1', 0.9458333333333333, 2.3480176211453743],\n",
       "  ['dpr-rate : 0.2', 0.9458333333333333, 2.33920704845815],\n",
       "  ['dpr-rate : 0.5', 0.9458333333333333, 2.39647577092511]]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 재형님 인코더\n",
    "score_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [['dpr-rate : 0.0', 0.55, 1.0],\n",
       "  ['dpr-rate : 0.1', 0.5708333333333333, 1.0],\n",
       "  ['dpr-rate : 0.2', 0.5958333333333333, 1.0],\n",
       "  ['dpr-rate : 0.5', 0.65, 1.0]],\n",
       " 10: [['dpr-rate : 0.0', 0.9041666666666667, 1.9262672811059909],\n",
       "  ['dpr-rate : 0.1', 0.9166666666666666, 1.9272727272727272],\n",
       "  ['dpr-rate : 0.2', 0.9166666666666666, 1.9227272727272726],\n",
       "  ['dpr-rate : 0.5', 0.9125, 1.8812785388127853]],\n",
       " 15: [['dpr-rate : 0.0', 0.9083333333333333, 1.981651376146789],\n",
       "  ['dpr-rate : 0.1', 0.9208333333333333, 1.9864253393665159],\n",
       "  ['dpr-rate : 0.2', 0.9208333333333333, 1.9819004524886878],\n",
       "  ['dpr-rate : 0.5', 0.9208333333333333, 1.9728506787330318]],\n",
       " 20: [['dpr-rate : 0.0', 0.9166666666666666, 2.1227272727272726],\n",
       "  ['dpr-rate : 0.1', 0.925, 2.063063063063063],\n",
       "  ['dpr-rate : 0.2', 0.9208333333333333, 1.9819004524886878],\n",
       "  ['dpr-rate : 0.5', 0.9208333333333333, 1.9728506787330318]],\n",
       " 30: [['dpr-rate : 0.0', 0.9541666666666667, 3.021834061135371],\n",
       "  ['dpr-rate : 0.1', 0.9375, 2.3644444444444446],\n",
       "  ['dpr-rate : 0.2', 0.9375, 2.3955555555555557],\n",
       "  ['dpr-rate : 0.5', 0.9291666666666667, 2.179372197309417]]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
